{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_letters = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vk_api\n",
    "import re\n",
    "# import sys\n",
    "import rus_preprocessing_udpipe\n",
    "from importlib import reload\n",
    "# reload(rus_preprocessing_udpipe)\n",
    "# import gensim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "from simple_elmo import ElmoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vk_session = vk_api.VkApi('+number', 'password')\n",
    "# vk_session.auth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vk_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get groups texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups_text(user_id, used_groups_limit, used_posts_num, vk_session):\n",
    "    groups = get_user_groups(user_id, vk_session)\n",
    "    groups_text, popular_words = get_groups_posts_text(groups, used_groups_limit, used_posts_num, vk_session)\n",
    "    return groups_text, popular_words\n",
    "\n",
    "\n",
    "def get_user_groups(user_id, vk_session):\n",
    "    return vk_session.method(\"groups.get\", values={\"user_id\": user_id})[\"items\"]\n",
    "\n",
    "\n",
    "def get_groups_posts_text(groups, used_groups_limit, used_posts_num, vk_session):\n",
    "#     global groups_texts\n",
    "    groups_texts = _raw_groups_texts(groups, used_groups_limit, used_posts_num, vk_session)\n",
    "    russian_texts, popular_words = extract_russian_words(groups_texts)\n",
    "    \n",
    "    return russian_texts, popular_words\n",
    "        \n",
    "def _raw_groups_texts(groups, used_groups_limit, used_posts_num, vk_session):\n",
    "    groups_texts = []\n",
    "\n",
    "    for idx, group in enumerate(groups[:used_groups_limit]):\n",
    "        try:\n",
    "            group_wall = vk_session.method(\"wall.get\", values={\"owner_id\": -group})\n",
    "            posts_texts = get_wall_texts(group_wall, used_posts_num)\n",
    "            posts_texts = \" \".join(posts_texts)\n",
    "            groups_texts.append(posts_texts)\n",
    "\n",
    "        except vk_api.ApiError:\n",
    "            print(\"Приватный паблик\")\n",
    "            \n",
    "    return groups_texts\n",
    "\n",
    "def extract_russian_words(groups_texts):\n",
    "    stop_words = get_stop_words(\"ru\")\n",
    "    \n",
    "#     concatenated_texts = \" \".join(groups_texts)\n",
    "    russian_texts = keep_russian_letters(groups_texts)\n",
    "    \n",
    "    for idx, text in enumerate(russian_texts):\n",
    "        filtered_words = [word for word in text.split() if word not in stop_words]\n",
    "        filtered_russian_text = \" \".join(filtered_words)\n",
    "        russian_texts[idx] = filtered_russian_text\n",
    "    \n",
    "    popular_words = get_popular_words(russian_texts)\n",
    "    \n",
    "    russian_texts = rus_preprocessing_udpipe.run(russian_texts)\n",
    "    return russian_texts, popular_words\n",
    "\n",
    "def get_wall_texts(wall, limit):\n",
    "    posts = wall[\"items\"]\n",
    "    posts_texts = []\n",
    "    for post in posts[:limit]:\n",
    "        posts_texts.append(post[\"text\"])\n",
    "        \n",
    "    return posts_texts\n",
    "\n",
    "def keep_russian_letters(texts):\n",
    "    for idx, text in enumerate(texts):\n",
    "        russian_text = \"\".join(re.findall(f\"[{russian_letters}\\s]\", text))\n",
    "        russian_text = re.sub(\"\\s\", \" \", russian_text)\n",
    "        texts[idx] = russian_text\n",
    "    \n",
    "    return texts\n",
    "\n",
    "def get_popular_words(texts):\n",
    "    concatenated_texts = \" \".join(texts)\n",
    "    groups_words = pd.Series(concatenated_texts.split())\n",
    "    counts = groups_words.value_counts().head(50)\n",
    "    return counts[counts.index.str.len() > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# groups_texts, popular_groups_words = get_groups_text(USER_ID)\n",
    "# groups_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# popular_groups_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get user wall texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_text(user_id, vk_session):\n",
    "    user_wall = vk_session.method(\"wall.get\", values={\"owner_id\": user_id})\n",
    "    posts_texts = get_wall_texts(user_wall, limit=5)\n",
    "    print(posts_texts)\n",
    "    russian_texts, popular_words = extract_russian_words(posts_texts)\n",
    "    return russian_texts, popular_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# user_texts, popular_user_words = get_user_text(USER_ID)\n",
    "# user_texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# model = ElmoModel()\n",
    "# model.load(\"196.zip\", max_batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(groups_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# groups_embedding = np.zeros(1024)\n",
    "# step = 10\n",
    "\n",
    "# for text_start_idx in range(0, len(groups_texts), step):\n",
    "#     text_end_idx = text_start_idx + step\n",
    "#     embeddings = model.get_elmo_vector_average(groups_texts[text_start_idx: text_end_idx])\n",
    "#     mean_embedding = embeddings.mean(axis=0)\n",
    "#     groups_embedding += mean_embedding\n",
    "#     del embeddings, mean_embedding\n",
    "    \n",
    "# groups_embedding /= ((len(groups_texts) + step - 1) // step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embeddings(user_id, vk_login, vk_password, elmo_model, used_groups_limit, used_posts_num):\n",
    "    vk_session = vk_api.VkApi(vk_login, vk_password)\n",
    "    vk_session.auth()\n",
    "    \n",
    "    groups_texts, popular_groups_words = get_groups_text(user_id, used_groups_limit, used_posts_num, vk_session)\n",
    "    \n",
    "    \n",
    "    groups_embedding = np.zeros(1024)\n",
    "    step = 10\n",
    "\n",
    "    for text_start_idx in range(0, len(groups_texts), step):\n",
    "        text_end_idx = text_start_idx + step\n",
    "        embeddings = elmo_model.get_elmo_vector_average(groups_texts[text_start_idx: text_end_idx])\n",
    "        mean_embedding = embeddings.mean(axis=0)\n",
    "        groups_embedding += mean_embedding\n",
    "        del embeddings, mean_embedding\n",
    "\n",
    "    groups_embedding /= ((len(groups_texts) + step - 1) // step)\n",
    "    \n",
    "    return groups_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the model...\n",
      "Processing input...\n",
      "2020-11-29 02:45:30,319 : INFO : Loading model from 196.zip...\n",
      "2020-11-29 02:45:30,320 : INFO : \n",
      "            Assuming the model is a ZIP archive downloaded from the NLPL vector repository.\n",
      "            Loading a model from a ZIP archive directly is slower than from the extracted files,\n",
      "            but does not require additional disk space\n",
      "            and allows to load from directories without write permissions.\n",
      "            \n",
      "2020-11-29 02:45:30,384 : INFO : We will cache the vocabulary of 100 tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gldsn/.local/share/virtualenvs/innohack-citadel-YNBG4hQA/lib/python3.8/site-packages/simple_elmo/model.py:529: LSTMCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-29 02:46:50,477 : WARNING : From /home/gldsn/.local/share/virtualenvs/innohack-citadel-YNBG4hQA/lib/python3.8/site-packages/simple_elmo/model.py:529: LSTMCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gldsn/.local/share/virtualenvs/innohack-citadel-YNBG4hQA/lib/python3.8/site-packages/simple_elmo/model.py:570: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-29 02:46:50,505 : WARNING : From /home/gldsn/.local/share/virtualenvs/innohack-citadel-YNBG4hQA/lib/python3.8/site-packages/simple_elmo/model.py:570: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gldsn/.local/share/virtualenvs/innohack-citadel-YNBG4hQA/lib/python3.8/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:962: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-29 02:46:50,744 : WARNING : From /home/gldsn/.local/share/virtualenvs/innohack-citadel-YNBG4hQA/lib/python3.8/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:962: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gldsn/.local/share/virtualenvs/innohack-citadel-YNBG4hQA/lib/python3.8/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:970: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-29 02:46:58,090 : WARNING : From /home/gldsn/.local/share/virtualenvs/innohack-citadel-YNBG4hQA/lib/python3.8/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:970: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "2020-11-29 02:48:15,535 : INFO : Warming up ELMo on 5 sentences...\n",
      "2020-11-29 02:48:30,406 : INFO : Warming up finished.\n",
      "2020-11-29 02:48:30,434 : INFO : Texts in the current batch: 5\n",
      "2020-11-29 02:48:44,748 : INFO : Texts in the current batch: 5\n"
     ]
    }
   ],
   "source": [
    "elmo_path = \"196.zip\"\n",
    "elmo_batch = 5\n",
    "USED_POSTS_NUM = 1\n",
    "used_groups_limit = 10\n",
    "USER_ID = \"gushchin_d\"\n",
    "model = ElmoModel()\n",
    "model.load(elmo_path, max_batch_size=elmo_batch)\n",
    "\n",
    "embedding = build_embeddings(USER_ID, \"+number\", \"password&R\", elmo_model, used_groups_limit, used_posts_num=USED_POSTS_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0235609 ,  0.00990808, -0.03002209, ..., -0.01308269,\n",
       "       -0.00175042, -0.03019912])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEGACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # категории подписок\n",
    "# subscriptions = vk_session.method(\"users.getSubscriptions\", values={\"user_id\": USER_ID})[\"groups\"][\"items\"]\n",
    "\n",
    "# for category_info in group_catalog_info[\"categories\"]:\n",
    "#     if category_info[\"name\"] not in [\"Популярные\", \"Бренды\"]:\n",
    "#         category = vk_session.method(\"groups.getCatalog\", values={\"category_id\": category_info[\"id\"]})\n",
    "#         print(\"category\", category_info[\"id\"])\n",
    "#         print(\"count\", category[\"count\"])\n",
    "#         print(category)\n",
    "\n",
    "# subscriptions = vk_session.method(\"users.getSubscriptions\", values={\"user_id\": USER_ID})[\"groups\"][\"items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subscriptions = vk_session.method(\"users.getSubscriptions\", values={\"user_id\": USER_ID})[\"groups\"][\"items\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
